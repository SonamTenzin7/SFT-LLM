{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff272320-bfe6-4467-812f-325806535dc0",
   "metadata": {},
   "source": [
    "# Supervised Fine-tuning Hermes-2-Pro-Llama-3-8B using Low-Rank Adaptation (LoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d063b34-0ba8-4bae-a8a4-2231ed448f68",
   "metadata": {},
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3907e93-b28f-4463-968a-c27518182060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629a6b07-a878-46cd-befc-9787efa40aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.36 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.55.0)\n",
      "Requirement already satisfied: datasets>=2.16 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: accelerate>=0.26 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: peft>=0.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.19 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.34.4)\n",
      "Requirement already satisfied: trl>=0.7 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.36) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub>=0.19) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub>=0.19) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface_hub>=0.19) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets>=2.16) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets>=2.16) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets>=2.16) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets>=2.16) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets>=2.16) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (3.9.5)\n",
      "Requirement already satisfied: psutil in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate>=0.26) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate>=0.26) (2.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (6.6.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16) (0.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers>=4.36) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers>=4.36) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers>=4.36) (2025.7.14)\n",
      "Requirement already satisfied: sympy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.26) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.26) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.26) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets>=2.16) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets>=2.16) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets>=2.16) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate>=0.26) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers>=4.36\" \"datasets>=2.16\" \"accelerate>=0.26\" \"peft>=0.17\" \"huggingface_hub>=0.19\" \"trl>=0.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6ae0ce-be32-4d59-9823-8bc9ba43b507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n",
      "4.55.0\n",
      "0.17.0\n",
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import trl, transformers, peft, accelerate\n",
    "print(trl.__version__)\n",
    "print(transformers.__version__)\n",
    "print(peft.__version__)\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468bcdeb-4c09-4bca-b886-41596c5e4a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.55.0\n",
      "Uninstalling transformers-4.55.0:\n",
      "  Successfully uninstalled transformers-4.55.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c750eeac-e8fc-4742-a5d0-da1776bcd0b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: trl 0.21.0\n",
      "Uninstalling trl-0.21.0:\n",
      "  Successfully uninstalled trl-0.21.0\n",
      "Collecting trl==0.4.7\n",
      "  Using cached trl-0.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from trl==0.4.7) (2.3.1)\n",
      "Collecting transformers>=4.18.0 (from trl==0.4.7)\n",
      "  Using cached transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from trl==0.4.7) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from trl==0.4.7) (1.10.0)\n",
      "Requirement already satisfied: datasets in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from trl==0.4.7) (4.0.0)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (4.14.1)\n",
      "Requirement already satisfied: sympy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.18.0->trl==0.4.7) (1.1.5)\n",
      "Requirement already satisfied: psutil in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate->trl==0.4.7) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets->trl==0.4.7) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets->trl==0.4.7) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets->trl==0.4.7) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets->trl==0.4.7) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets->trl==0.4.7) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (6.6.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.4.7) (0.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.7) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.4.7) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.7) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.4.7) (1.3.0)\n",
      "Using cached trl-0.4.7-py3-none-any.whl (77 kB)\n",
      "Using cached transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "Installing collected packages: transformers, trl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [trl]\u001b[32m1/2\u001b[0m [trl]\n",
      "Successfully installed transformers-4.55.0 trl-0.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y trl\n",
    "!pip install \"trl==0.4.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846ed8ee-4590-4874-9ad7-d301cb59017e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: numpy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.55.0)\n",
      "Requirement already satisfied: datasets in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: accelerate in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: peft in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: trl in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.4.7)\n",
      "Collecting trl\n",
      "  Using cached trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.9.5)\n",
      "Requirement already satisfied: psutil in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: sympy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Using cached trl-0.21.0-py3-none-any.whl (511 kB)\n",
      "Installing collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.4.7\n",
      "    Uninstalling trl-0.4.7:\n",
      "      Successfully uninstalled trl-0.4.7\n",
      "Successfully installed trl-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install --upgrade transformers datasets accelerate peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b9fb6d-a3a6-4405-9814-f34896dc0da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.3.1)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.18.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.23.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: torchaudio in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.3.1)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: numpy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.8.0-cp310-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "Using cached torchvision-0.23.0-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached torchaudio-2.8.0-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: torch\n",
      "\u001b[2K    Found existing installation: torch 2.3.1\n",
      "\u001b[2K    Uninstalling torch-2.3.1:\n",
      "\u001b[2K      Successfully uninstalled torch-2.3.1━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.18.132m0/3\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.18.1:━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.18.1\u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudiom\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.3.1━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.3.1:0m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.3.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [torchaudio]m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch-2.8.0 torchaudio-2.8.0 torchvision-0.23.0\n",
      "Collecting torch==2.3.1\n",
      "  Using cached torch-2.3.1-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.18.1\n",
      "  Using cached torchvision-0.18.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio==2.3.1\n",
      "  Using cached torchaudio-2.3.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch==2.3.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch==2.3.1) (4.14.1)\n",
      "Requirement already satisfied: sympy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch==2.3.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch==2.3.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch==2.3.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch==2.3.1) (2024.12.0)\n",
      "Requirement already satisfied: numpy in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torchvision==0.18.1) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torchvision==0.18.1) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "Using cached torch-2.3.1-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "Using cached torchvision-0.18.1-cp310-cp310-macosx_11_0_arm64.whl (1.6 MB)\n",
      "Using cached torchaudio-2.3.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: torch\n",
      "\u001b[2K    Found existing installation: torch 2.8.0\n",
      "\u001b[2K    Uninstalling torch-2.8.0:\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.23.032m0/3\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.23.0:━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.23.0\u001b[32m0/3\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudiom\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.8.0━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.8.0:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [torchaudio]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.8.00m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [torchaudio]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [torchaudio]m [torchaudio]\n",
      "Successfully installed torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio\n",
    "\n",
    "# installing latest stable \n",
    "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcc79b0-3f73-41be-b723-862bb8c83cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "# Check device Metal Performance Shaders for GPU acceleration (Mac)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca5450-75ca-4c1e-afbc-adbd4b227088",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad53feb-3d13-4b73-8eb3-b74372ea40c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 89\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"sonamtenzey/instruction_dataset-edu-ai\")\n",
    "print(\"Dataset Loaded\", ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5399b9-f737-4685-b64a-b5d053a6a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds[\"train\"].train_test_split(test_size=0.1)\n",
    "# ds['validation'] = ds.pop('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3e63c-199e-49fc-af84-507e9b17d83c",
   "metadata": {},
   "source": [
    "## Formating Dataset for Instruction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a1cc49-8fbe-4cc2-a5c6-3f527fd117c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_instruction(example):\n",
    "    messages = example[\"messages\"]\n",
    "    instruction = \"\"\n",
    "    input_text = \"\"\n",
    "    response = \"\"\n",
    "\n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            if not instruction:\n",
    "                instruction = msg[\"content\"]\n",
    "            else:\n",
    "                input_text = msg[\"content\"]  \n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            response = msg[\"content\"]\n",
    "\n",
    "    text = f\"### Instruction:\\n{instruction}\\n\\n\"\n",
    "    if input_text.strip():\n",
    "        text += f\"### Input:\\n{input_text}\\n\\n\"\n",
    "    text += f\"### Response:\\n{response}</s>\"\n",
    "\n",
    "    return {\"text\": text}  \n",
    "\n",
    "# Apply formatting\n",
    "ds_formatted = ds[\"train\"].map(format_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323739eb-f56e-4206-87b1-6eb3f265de2c",
   "metadata": {},
   "source": [
    "## Load Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ae1f92-0475-4f26-96f8-87b384ee5473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73b64d0706f497da185052302111b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"NousResearch/Hermes-2-Pro-Llama-3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None,\n",
    "    low_cpu_mem_usage=False,\n",
    ").to(device)\n",
    "\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637100d-7d92-43e6-8420-51fe0fbbcc5c",
   "metadata": {},
   "source": [
    "## Adding LoRA (Parameter_Efficient_Fine_Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca584be-e1d3-446b-98ec-5e76cf5c7c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 8-bit optimizer is not available on your device, only available on CUDA for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 54,525,952 || all params: 8,085,049,344 || trainable%: 0.6744\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "# Should show ~0.5% trainable params (e.g., 20M/4B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b5868-ea36-44c7-bb12-9e147f80749c",
   "metadata": {},
   "source": [
    "## Setting up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23fc647-0f5b-434d-854b-7e4a50461ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./lora-finetuned-hermes\",\n",
    "    logging_dir = \"./lora-finetuned-hermes/logs\",\n",
    "    \n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=1,\n",
    "    save_steps=5,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end = \"eval_loss\",\n",
    "    greater_is_better =False,\n",
    "    report_to=\"none\",\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_steps=2,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    fp16=False,\n",
    "    bf16=False,  # Enable if supported (e.g., CUDA/Ampere+)\n",
    "    seed=42,\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    \n",
    "\n",
    "    # Dataset processing\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": True,\n",
    "        \"packing\": False,\n",
    "        \"max_seq_length\": 1024,\n",
    "    },\n",
    "    dataset_text_field=\"messages\",  \n",
    "    dataset_num_proc=2,\n",
    "\n",
    "    eval_strategy= \"steps\",\n",
    "    eval_steps = 5,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ae153a-97ff-44fa-a8af-bf9d59582eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train and validation...\n"
     ]
    }
   ],
   "source": [
    "if \"validation\" not in ds:\n",
    "    print(\"Splitting dataset into train and validation...\")\n",
    "    split = ds[\"train\"].train_test_split(test_size=0.15, seed=42)\n",
    "    train_dataset = split[\"train\"]\n",
    "    eval_dataset = split[\"test\"]  # will be used as validation\n",
    "else:\n",
    "    train_dataset = ds[\"train\"]\n",
    "    eval_dataset = ds[\"validation\"]\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,   \n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300cf025-ca94-4a37-b7ff-7d6f1a0c44e5",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c192d5e5-91dd-4ccc-896d-958f9f59f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 14:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.686200</td>\n",
       "      <td>1.847971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.050600</td>\n",
       "      <td>1.060169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.682192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.641366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 694253ee-6f8d-4e0d-bdde-8b09594262b8)') - silently ignoring the lookup for the file config.json in NousResearch/Hermes-2-Pro-Llama-3-8B.\n",
      "  warnings.warn(\n",
      "/Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in NousResearch/Hermes-2-Pro-Llama-3-8B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./lora-finetuned-hermes\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save adapter (LoRA weights only ~100MB) \n",
    "trainer.save_model()\n",
    "print(\"Model saved to ./lora-finetuned-hermes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69d79d76-0b64-4f45-9747-a84dd3923347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Eval Loss = 1.8480\n",
      "Step 10: Eval Loss = 1.0602\n",
      "Step 15: Eval Loss = 0.6822\n",
      "Step 20: Eval Loss = 0.6414\n"
     ]
    }
   ],
   "source": [
    "for log in trainer.state.log_history:\n",
    "    if \"eval_loss\" in log:\n",
    "        print(f\"Step {log.get('step', '??')}: Eval Loss = {log['eval_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c62027-a8e5-4678-ab51-d4a015e635cb",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81fbc452-7ef0-4e8b-92e3-569a06e001e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonamtenzin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/pytorch_utils.py:333: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"analysis_text\": \"Here is a table comparing the key performance indicators of Druk School and Ugyen Academy:\", \"chart\": {\"type\": \"table\", \"data\": {\"columns\": [{\"label\": \"School\", \"type\": \"string\"}, {\"label\": \"Average Score\", \"type\": \"number\"}, {\"label\": \"Pass Rate\", \"type\": \"number\"}, {\"label\": \"Attendance\", \"type\": \"number\"}], \"rows\": [{\"data\": [\"Druk School\", 88, 95, 97]}, {\"data\": [\"Ugyen Academy\", 91, 98, 96]}]}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def generate_response(instruction, input_data=None):\n",
    "    \"\"\"\n",
    "    Generate response using the same ChatML format used in training.\n",
    "    \"\"\"\n",
    "    # Format input data as JSON string if provided\n",
    "    data_str = json.dumps(input_data, indent=2) if input_data else \"\"\n",
    "\n",
    "    # Construct messages in the same structure as training\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a specialized AI assistant for Bhutanese schools, designed to generate factual reports from educational data. You must follow these rules:\\n1. Your response MUST be a valid JSON object with two keys: 'analysis_text' (string) and 'chart' (object or null).\\n2. 'chart' MUST be null if no data visualization is requested, relevant, or possible.\\n3. Do NOT make up data, scores, or facts. Only use provided information.\\n4. If the question is about you (e.g., 'Who are you?'), briefly describe your role in 'analysis_text' and set 'chart' to null.\\n5. Never generate markdown, code blocks, or explanations outside JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Instruction: {instruction}\\n\\nData:\\n{data_str}\"},\n",
    "    ]\n",
    "\n",
    "    # Apply the same ChatML template used in training\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        temperature=None,\n",
    "        top_p=None,\n",
    "    )\n",
    "\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # Extract only assistant's response\n",
    "    start_token = \"<|im_start|>assistant\"\n",
    "    end_token = \"<|im_end|>\"\n",
    "\n",
    "    if start_token in full_response:\n",
    "        start_idx = full_response.index(start_token) + len(start_token)\n",
    "        response_part = full_response[start_idx:].strip()\n",
    "        # Remove trailing eos or im_end if present\n",
    "        if end_token in response_part:\n",
    "            response_part = response_part.split(end_token)[0].strip()\n",
    "        return response_part\n",
    "    else:\n",
    "        return \"Model did not generate a valid assistant response.\"\n",
    "\n",
    "# Test case\n",
    "instruction = \"Create a table to compare the key performance indicators of Druk School and Ugyen Academy.\" \n",
    "input_data = [  \n",
    "  {\"school\": \"Druk School\", \"avg_score\": 88, \"pass_rate\": 95, \"attendance\": 97},\n",
    "  {\"school\": \"Ugyen Academy\", \"avg_score\": 91, \"pass_rate\": 98, \"attendance\": 96}]\n",
    "\n",
    "\n",
    "print(\"--- Testing Model ---\")\n",
    "response = generate_response(instruction, input_data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33121f12-9f40-4087-b195-83db45fb9050",
   "metadata": {},
   "source": [
    "## Reloading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0396f204-5509-44cf-af9b-6230a4e4da22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98cdbc7306a4af0a24cbbea4741fd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 8-bit optimizer is not available on your device, only available on CUDA for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapter...\n",
      "Merging LoRA weights into base model...\n",
      "Saving merged model and tokenizer to ./merged-hermes-2-pro-lora...\n",
      "Model and tokenizer loaded successfully!\n",
      "Model and tokenizer saved successfully to ./merged-hermes-2-pro-lora!\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Define device\n",
    "device = (\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "model_name = \"NousResearch/Hermes-2-Pro-Llama-3-8B\"\n",
    "lora_path = \"./lora-finetuned-hermes\"\n",
    "offload_folder = \"./offload\"\n",
    "merged_model_path = \"./merged-hermes-2-pro-lora\"\n",
    "os.makedirs(offload_folder, exist_ok=True)\n",
    "os.makedirs(merged_model_path, exist_ok=True)\n",
    "\n",
    "# Tokenizer: Load from base model, not LoRA\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"  # Important for generation\n",
    "\n",
    "# Set dtype based on device\n",
    "if device == \"mps\":\n",
    "    torch_dtype = torch.float16  # Or torch.float32 if needed\n",
    "elif torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "\n",
    "# Load base model with device_map only (no .to(device))\n",
    "print(\"Loading base model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None,\n",
    "    low_cpu_mem_usage=False,\n",
    ").to(device)\n",
    "\n",
    "# Apply LoRA adapter\n",
    "print(\"Applying LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    lora_path,\n",
    "    offload_folder=offload_folder,\n",
    ")\n",
    "\n",
    "# Merge LoRA weights\n",
    "print(\"Merging LoRA weights into base model...\")\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Save the merged model and tokenizer\n",
    "print(f\"Saving merged model and tokenizer to {merged_model_path}...\")\n",
    "model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n",
    "print(\"Model and tokenizer loaded successfully!\")\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to {merged_model_path}!\")\n",
    "\n",
    "# outputs = model.generate(\n",
    "#     **inputs,\n",
    "#     max_new_tokens=150,\n",
    "#     temperature=0.7,\n",
    "#     do_sample=True,\n",
    "#     pad_token_id=tokenizer.eos_token_id,\n",
    "# )\n",
    "# print(\"Response:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db801c1a-d636-4f1e-aac9-abc484171345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing Model ---\n",
      "{\"analysis_text\": \"Dagana Primary School's student performance in First Term, 2025, is detailed below.\", \"chart\": {\"type\": \"bar\", \"title\": \"Subject-wise Performance of Students\", \"data\": {\"labels\": [\"Tashi\", \"Dorji\", \"Nima\"], \"datasets\": [{\"label\": \"Math\", \"data\": [78.5, 63.7, 85.0]}, {\"label\": \"English\", \"data\": [69.2, 71.5, 80.4]}, {\"label\": \"Dzongkha\", \"data\": [82.0, 76.8, 78.9]}, {\"label\": \"Science\", \"data\": [74.3, 60.0, 82.1]}]}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def generate_response(instruction, input_data=None):\n",
    "    \"\"\"\n",
    "    Generate response using the same ChatML format used in training.\n",
    "    \"\"\"\n",
    "    # Format input data as JSON string if provided\n",
    "    data_str = json.dumps(input_data, indent=2) if input_data else \"\"\n",
    "\n",
    "    # Construct messages in the same structure as training\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a specialized AI assistant for Bhutanese schools, designed to generate factual reports from educational data. You must follow these rules:\\n1. Your response MUST be a valid JSON object with two keys: 'analysis_text' (string) and 'chart' (object or null).\\n2. 'chart' MUST be null if no data visualization is requested, relevant, or possible.\\n3. Do NOT make up data, scores, or facts. Only use provided information.\\n4. If the question is about you (e.g., 'Who are you?'), briefly describe your role in 'analysis_text' and set 'chart' to null.\\n5. Never generate markdown, code blocks, or explanations outside JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Instruction: {instruction}\\n\\nData:\\n{data_str}\"},\n",
    "    ]\n",
    "\n",
    "    # Apply the same ChatML template used in training\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        temperature=None,\n",
    "        top_p=None,\n",
    "    )\n",
    "\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # Extract only assistant's response\n",
    "    start_token = \"<|im_start|>assistant\"\n",
    "    end_token = \"<|im_end|>\"\n",
    "\n",
    "    if start_token in full_response:\n",
    "        start_idx = full_response.index(start_token) + len(start_token)\n",
    "        response_part = full_response[start_idx:].strip()\n",
    "        # Remove trailing eos or im_end if present\n",
    "        if end_token in response_part:\n",
    "            response_part = response_part.split(end_token)[0].strip()\n",
    "        return response_part\n",
    "    else:\n",
    "        return \"Model did not generate a valid assistant response.\"\n",
    "\n",
    "# Test case\n",
    "instruction = \"Generate a detailed and diagrammatic report for Dagana Primary School based on the provided student data\" \n",
    "input_data = {\n",
    "  \"school\": \"Dagana Primary School\",\n",
    "  \"academic_term\": \"First Term, 2025\",\n",
    "  \"students\": [\n",
    "    {\n",
    "      \"student_name\": \"Tashi\",\n",
    "      \"present\": 76,\n",
    "      \"total_days\": 88,\n",
    "      \"math\": 78.5,\n",
    "      \"english\": 69.2,\n",
    "      \"dzongkha\": 82.0,\n",
    "      \"science\": 74.3\n",
    "    },\n",
    "    {\n",
    "      \"student_name\": \"Dorji\",\n",
    "      \"present\": 68,\n",
    "      \"total_days\": 88,\n",
    "      \"math\": 63.7,\n",
    "      \"english\": 71.5,\n",
    "      \"dzongkha\": 76.8,\n",
    "      \"science\": 60.0\n",
    "    },\n",
    "    {\n",
    "      \"student_name\": \"Nima\",\n",
    "      \"present\": 84,\n",
    "      \"total_days\": 88,\n",
    "      \"math\": 85.0,\n",
    "      \"english\": 80.4,\n",
    "      \"dzongkha\": 78.9,\n",
    "      \"science\": 82.1\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "print(\"--- Testing Model ---\")\n",
    "response = generate_response(instruction, input_data)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - EduAI",
   "language": "python",
   "name": "mac-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
